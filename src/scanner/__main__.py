"""
Scanner CLI

ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰ãƒãƒ«ãƒãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¹ã‚­ãƒ£ãƒ³ã‚’å®Ÿè¡Œ

Usage:
    python -m scanner scan          # å…¨ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¹ã‚­ãƒ£ãƒ³
    python -m scanner scan --no-cloud  # ãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿
    python -m scanner status        # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªè¡¨ç¤º
    python -m scanner detect        # ãƒ¬ã‚¬ã‚·ãƒ¼äº’æ›ï¼ˆLM Studioã®ã¿ï¼‰
"""

import sys
import io
import argparse
import asyncio
import logging
from pathlib import Path

# Windowsç’°å¢ƒã§ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œ
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")

from .scanner import MultiRuntimeScanner
from .registry import ModelRegistry
from .runtime_info import ModelSource

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆåŸºæº–ã®ãƒ¬ã‚¸ã‚¹ãƒˆãƒªãƒ‘ã‚¹ (src/ ã®è¦ª)
_PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
_DEFAULT_REGISTRY = str(_PROJECT_ROOT / "data" / "model_registry.json")


def setup_logging(verbose: bool = False):
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(level=level, format="%(levelname)s: %(message)s")


def cmd_scan(args):
    """å…¨ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¹ã‚­ãƒ£ãƒ³"""
    include_cloud = not args.no_cloud
    scanner = MultiRuntimeScanner(
        timeout=args.timeout,
        include_cloud=include_cloud,
    )

    print(f"ã‚¹ã‚­ãƒ£ãƒ³ä¸­... (ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {args.timeout}ç§’)")

    results = asyncio.run(scanner.scan_all())

    if not results:
        print("\næ¤œå‡ºã•ã‚ŒãŸãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“")
        print("  LM Studio, Ollama ç­‰ã‚’èµ·å‹•ã—ã¦ãã ã•ã„")
        return 1

    # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«ä¿å­˜
    registry = ModelRegistry(cache_path=args.registry)
    registry.update(results)

    print(f"\n{'='*60}")
    print(f"ã‚¹ã‚­ãƒ£ãƒ³çµæœ: {registry.get_total_count()}ãƒ¢ãƒ‡ãƒ«æ¤œå‡º")
    print(f"{'='*60}")

    for runtime_key, models in results.items():
        icon = "â˜ï¸" if runtime_key == "cloud" else "ğŸ’»"
        print(f"\n{icon} {runtime_key}: {len(models)}ãƒ¢ãƒ‡ãƒ«")
        for model in models:
            print(f"  - {model.id}")
            if model.description:
                print(f"    {model.description}")

    print(f"\nãƒ¬ã‚¸ã‚¹ãƒˆãƒªä¿å­˜å…ˆ: {args.registry}")
    return 0


def cmd_status(args):
    """ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã®ç¾åœ¨çŠ¶æ…‹ã‚’è¡¨ç¤º"""
    registry = ModelRegistry(cache_path=args.registry)

    if registry.get_total_count() == 0:
        print("ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã¯ç©ºã§ã™ã€‚`python -m scanner scan` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return 1

    valid = registry.is_cache_valid()
    print(f"æœ€çµ‚ã‚¹ã‚­ãƒ£ãƒ³: {registry.last_scan_iso or 'ä¸æ˜'}")
    print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥: {'æœ‰åŠ¹' if valid else 'æœŸé™åˆ‡ã‚Œ'}")
    print(f"{'='*60}")

    local_models = registry.get_local_models()
    cloud_models = registry.get_cloud_models()

    if local_models:
        print(f"\nğŸ’» ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«: {len(local_models)}å€‹")
        for m in local_models:
            rt = m.runtime.runtime_type.value if m.runtime else "?"
            port = m.runtime.port if m.runtime else "?"
            print(f"  [{rt}:{port}] {m.id}")

    if cloud_models:
        print(f"\nâ˜ï¸ ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¢ãƒ‡ãƒ«: {len(cloud_models)}å€‹")
        for m in cloud_models:
            key_status = "âœ“" if m.api_key_present else "âœ—"
            print(f"  [{m.provider} {key_status}] {m.id} - {m.name}")

    return 0


def cmd_detect(args):
    """ãƒ¬ã‚¬ã‚·ãƒ¼äº’æ›: LM Studioã®ã¿æ¤œå‡º"""
    from .runtime_detectors import LMStudioDetector

    port = 1234
    detector = LMStudioDetector("localhost", port, timeout=args.timeout)

    print(f"LM Studio (localhost:{port}) ã«æ¥ç¶šä¸­...")

    async def _run():
        detected, runtime_info = await detector.detect()
        if not detected:
            return None, []
        models = await detector.get_models(runtime_info)
        return runtime_info, models

    runtime_info, models = asyncio.run(_run())

    if runtime_info is None:
        print("LM StudioãŒèµ·å‹•ã—ã¦ã„ãªã„ã‹ã€æ¥ç¶šã§ãã¾ã›ã‚“")
        return 1

    print(f"LM Studioæ¤œå‡º ({runtime_info.response_time_ms:.0f}ms)\n")

    if not models:
        print("ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return 1

    print(f"æ¤œå‡ºãƒ¢ãƒ‡ãƒ«: {len(models)}å€‹\n")
    for i, model in enumerate(models, 1):
        default_mark = " [ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ]" if i == 1 else ""
        print(f"  {i}. {model.id}{default_mark}")

    return 0


def main():
    parser = argparse.ArgumentParser(
        prog="python -m scanner",
        description="LLM Runtime Scanner - ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒ©ãƒ³ã‚¿ã‚¤ãƒ è‡ªå‹•æ¤œå‡º",
    )
    parser.add_argument("-v", "--verbose", action="store_true", help="è©³ç´°ãƒ­ã‚°")
    parser.add_argument(
        "--registry",
        default=_DEFAULT_REGISTRY,
        help="ãƒ¬ã‚¸ã‚¹ãƒˆãƒªJSONä¿å­˜å…ˆ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: <project_root>/data/model_registry.json)",
    )

    subparsers = parser.add_subparsers(dest="command", help="ã‚³ãƒãƒ³ãƒ‰")

    # scan
    scan_p = subparsers.add_parser("scan", help="å…¨ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¹ã‚­ãƒ£ãƒ³")
    scan_p.add_argument("--timeout", type=float, default=2.0, help="ãƒãƒ¼ãƒˆã‚ãŸã‚Šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ(ç§’)")
    scan_p.add_argument("--no-cloud", action="store_true", help="ã‚¯ãƒ©ã‚¦ãƒ‰æ¤œå‡ºã‚’ã‚¹ã‚­ãƒƒãƒ—")
    scan_p.set_defaults(func=cmd_scan)

    # status
    status_p = subparsers.add_parser("status", help="ãƒ¬ã‚¸ã‚¹ãƒˆãƒªçŠ¶æ…‹è¡¨ç¤º")
    status_p.set_defaults(func=cmd_status)

    # detect (ãƒ¬ã‚¬ã‚·ãƒ¼)
    detect_p = subparsers.add_parser("detect", help="LM Studioãƒ¢ãƒ‡ãƒ«æ¤œå‡º (ãƒ¬ã‚¬ã‚·ãƒ¼)")
    detect_p.add_argument("--timeout", type=float, default=5.0)
    detect_p.set_defaults(func=cmd_detect)

    if len(sys.argv) == 1:
        parser.print_help()
        return 1

    args = parser.parse_args()
    setup_logging(args.verbose)

    if hasattr(args, "func"):
        return args.func(args)
    parser.print_help()
    return 1


if __name__ == "__main__":
    sys.exit(main())
