# LM Studio Model Detector

LLM Smart Routerç”¨ã®LM Studioãƒ¢ãƒ‡ãƒ«è‡ªå‹•æ¤œå‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

## æ©Ÿèƒ½

- **ãƒ¢ãƒ‡ãƒ«è‡ªå‹•æ¤œå‡º**: LM Studioã®OpenAIäº’æ›APIã‚’ä½¿ç”¨ã—ã¦èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œå‡º
- **è¨­å®šè‡ªå‹•æ›´æ–°**: `config.yaml` ã‚’æ¤œå‡ºã—ãŸãƒ¢ãƒ‡ãƒ«æƒ…å ±ã§è‡ªå‹•æ›´æ–°
- **è¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ**: èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’å€‹åˆ¥ã«ç®¡ç†
- **CLIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰ç°¡å˜ã«æ“ä½œ

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# requirements.txtã«è¿½åŠ 
requests>=2.28.0
pyyaml>=6.0
```

## ä½¿ç”¨æ–¹æ³•

### CLIã‚³ãƒãƒ³ãƒ‰

```bash
# ãƒ¢ãƒ‡ãƒ«æ¤œå‡ºã—ã¦è¡¨ç¤º
python -m lmstudio detect

# æ¤œå‡ºã—ã¦config.yamlã‚’æ›´æ–°
python -m lmstudio update

# LM StudioçŠ¶æ…‹ç¢ºèª
python -m lmstudio status

# ãƒ¢ãƒ‡ãƒ«ä¸€è¦§è¡¨ç¤ºï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ï¼‰
python -m lmstudio list

# ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æŒ‡å®š
python -m lmstudio detect --endpoint http://192.168.1.100:1234/v1
```

### Python API

```python
from lmstudio import LMStudioModelDetector

# æ¤œå‡ºå™¨ã®åˆæœŸåŒ–
detector = LMStudioModelDetector(endpoint="http://localhost:1234/v1")

# LM StudioãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
if detector.is_running():
    # èª­ã¿è¾¼ã¿ä¸­ã®ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
    models = detector.get_loaded_models()
    for model in models:
        print(f"{model.id}: {model.name}")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
    default = detector.get_default_model()
    print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {default}")
    
    # config.yamlã‚’æ›´æ–°
    result = detector.detect_and_update_config("./config.yaml")
    print(f"æ›´æ–°æˆåŠŸ: {result['success']}")
```

### router.jsã¨ã®é€£æº

```javascript
// router.js èµ·å‹•æ™‚ã«è‡ªå‹•æ¤œå‡º
import { execSync } from 'child_process';

class LLMRouter {
  constructor(configPath = './config.yaml') {
    // LM Studioãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•æ¤œå‡º
    this.detectLMStudioModels(configPath);
    
    // è¨­å®šã‚’èª­ã¿è¾¼ã¿
    this.config = yaml.load(fs.readFileSync(configPath, 'utf8'));
    // ...
  }
  
  detectLMStudioModels(configPath) {
    try {
      console.log('ğŸ” LM Studioãƒ¢ãƒ‡ãƒ«ã‚’æ¤œå‡ºä¸­...');
      const result = execSync(`python -m lmstudio update --config ${configPath}`, {
        encoding: 'utf8',
        timeout: 10000
      });
      console.log(result);
    } catch (error) {
      console.log('âš ï¸  LM Studioæ¤œå‡ºã«å¤±æ•—ã€æ—¢å­˜è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™');
    }
  }
}
```

## è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 

`python -m lmstudio update` ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ã«æ›´æ–°ã•ã‚Œã¾ã™:

```yaml
models:
  local:
    endpoint: http://localhost:1234/v1
    model: detected-model-id  # â† è‡ªå‹•æ›´æ–°
    temperature: 0.7
    max_tokens: 2048
    timeout: 30000
  
  # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ
  lmstudio:
    endpoint: http://localhost:1234/v1
    model: first-model-id
    name: "First Model"
  
  lmstudio_1:
    endpoint: http://localhost:1234/v1
    model: second-model-id
    name: "Second Model"

lmstudio_meta:
  last_detected: first-model-id
  detected_models:
    - first-model-id
    - second-model-id
```

## ãƒ†ã‚¹ãƒˆ

```bash
# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
python -m pytest src/tests/test_lmstudio.py -v

# ã‚«ãƒãƒ¬ãƒƒã‚¸ä»˜ã
python -m pytest src/tests/test_lmstudio.py --cov=lmstudio --cov-report=html
```

## LM Studioè¨­å®š

1. LM Studioã‚’èµ·å‹•
2. ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
3. ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ï¼ˆOpenAIäº’æ›APIæœ‰åŠ¹ï¼‰
4. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ `http://localhost:1234/v1` ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

| å•é¡Œ | è§£æ±ºç­– |
|------|--------|
| Connection refused | LM StudioãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª |
| ãƒ¢ãƒ‡ãƒ«ãŒæ¤œå‡ºã•ã‚Œãªã„ | LM Studioã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã‚‹ã‹ç¢ºèª |
| ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ | ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLãŒæ­£ã—ã„ã‹ç¢ºèª |

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT
